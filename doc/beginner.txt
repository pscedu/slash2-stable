some data structures get registered for statistics exportation and
manipulation through daemon control sockets, for example, the
free read buffer list in zest is accessible like this:

  $ zestiondctl -Lreadfree

how to view manpages:

  $ nroff -mandoc foo.1

and usually pipe it to a pager or somewhere...

building how-to for most programs: try "make build" first.
if make(1) complains there is no "build" target, then execute:

  $ make clean
  $ make depend
  $ make

you should re-run "make depend" anytime any file changes/adds/removes a #include
directive so file dependences are properly maintained.

other make targets.  to create a recursive code database for use with vim, use
the cscope target:

  $ make cs

emacs:

  $ make etags

it is advised to check code against lint from time to time:

  $ make lint

most targets are recursive.  there are other tricks in $PROJ_BASE/mk/main.mk.

you should not commit to example configuration files or files called "local*"
unless you know what you're doing, otherwise it may cause may SVN merge conflicts
for everyone else (including yourself)

lnet-lite - lower level networking library
mk - global build infrastructure
	each project contains additional build rules and settings
	(such as include file directories pertinent to its various sources)
psc_fsutil_libs (PFL) - common data structures and routines
    include - header files
	psc_types - basic data types
	psc_ds - code implementing various data structures
		dynarray - dynamically resizable arrays using realloc()
		hash - hash table
			(o) automatically registered for export/control
		stree - simple tree where each node may have a variable
			number of branches/children
		vbitmap - arbitrarily-sized bitmaps (byte strings)
		list - linux/list.h rewrite, lightweight linked list implementation,
			NOT thread-safe (these routines must be invoked mutually
			exclusive sections of code e.g. protected by spinlocks)
		listcache - heavier duty linked list, thread-safe
			(o) automatically registered for export/control
		tree - BSD sys/tree.h, contains two types of trees:
			(o) splay - auto-rebalancing two-child-node tree
			(o) red-black - glorified binary search tree
			documentation for this file is here:
			http://www.openbsd.org/cgi-bin/man.cgi?query=tree
	psc_rpc - remote procedure call (RPC) library which leverages
	    the LNET networking library
		rsx - interface for simple RPC message communication
		the other files are split/shared between client/server activity

		the zest client has an asynchronous I/O example
	psc_util - miscellaneous utility routines
		alloc - validity-checked allocation routines
		assert - assertions tied to logging system
		atomic - a data type which provies a variety of mathematical operations
			which by nature of atomic i.e mutually exclusive, ideal e.g. for
			thread-shared data structures containing members which need
			to be updated but shouldn't require the overhead of locking the
			structure
		cdefs - miscellaneous C definitions
		crc - cyclic redundancy checks for attempting to verify data integrity
		ctlcli - client interface for daemon control
		ctlsvr - server guts for daemon control
		fmtstr - custom format strings, e.g. %M for minutes, %H for hours, etc.
		init - PFL initialization, key data structures and threads, etc.
		iostats - routines for gathering statistics about any form of I/O
			(o) automatically registered for export/control
		journal - cheesy (atm) journaling routines
		lock - simple spinlock implementation for mutually exclusive code sections
			spinlock() - necessarily acquire a spinlock,
				blocking until release if already held by another thread
			freelock() - release a held spinlock
			trylock() - attempt to grab a spinlock, returning false if another
				thread already holds it

			reqlock() - require a spinlock for a section,
				ideal for recursive or highly nested program structure
			ureqlock() - (possibly) release a required lock,
				if not already held before corresponding reqlock()
		log - fine-grained logging API
			in PFL programs, there are a number of subsystems a program
			may register, e.g. in zest there is an inode subsystem which
			tracks open/active files, syncer subsystem in charge of moving
			data chunks to third-party file systems, parity rebuild subsystem
			in charge of reconstructing lost blocks, etc.

			each subsystem has a loglevel associated with it which describes
			which kinds of messages (by severity) may be reported, and each
			thread has its own set of values for these.  these levels are
			all controllable via the control interface
			(o) automatically registered for export/control

			psc_trace()	flow report
			psc_info()	informational/diagnostic message
			psc_dbg()	debugging messages
			psc_notice()	condition alert
			psc_warn()	non-critical error, append errno
			psc_warnx()	non-critical error, not system-related
			psc_error()	serious error, append errno to message
			psc_errorx()	serious error, not system-related
			psc_fatal()	fatal error, end program execution, with errno
			psc_fatalx()	fatal error, end program execution, not sys-related

		mkdirs - mkdir -p in a function
		palloc - page-aligned alloc, necessary for some kinds of I/O and performance
		printhex - simple data printer in hexadecimal for debugging
		pthread_barrier - thread barriers, for sync'ing everyone up before
			proceeding to further workloads
		random - pseudo-random number generator based on /dev/urandom
		strlcpy - OpenBSD's NUL-guaranteed truncation-detecting strncpy
		subsys - routines relating to the "subsystem" facility which may be used
			to logically divide large program structure into modules
		thread - layer above pthread which gives you many things (basically,
			all thread-safe code in PFL deals with pscthreads and not
			pthreads directly)
		threadtable - hash table of threads, for looking yourself up to access
			thread-local data
		waitq - wait on an event, from the context of a thread
slash_nara - root of slash-specific code
	include - shared include files
		buffer - slab buffers for memory-resident file portions
		fid - global file ID definitions
		fidcache - managing a collection of in-core files
		inode - one in-core file
		offtree - "offset tree" for connecting file-logical positions
			to slab buffers efficiently
		slashrpc - slash RPC definitions
		slconfig - lex-based configuration parser definitions
	mk - slash-specific build rules/definitions/customizations/etc.
	mount_slash - fuse mounter for slash, connects to slashd and sliod
		control - control interface definitions
		mount_slash.c - core program definitions
		rpc - RPC routines specific to mount_slash
	msctl - command-line mount_slash controller
	newfs_slio - sets up a new file system for use with sliod
	newfs_slmd - sets up a new file system for use with slashd
	share - code amongst several slash-related programs
	slashd - MDS server
		backend - inter- MDS and I/O daemon communication
		cfd - "client file descriptor" routines, which tracks client-scoped
			identifiers with active files
		control - control interface definitions
		dircache - cache for open(2) directory handles for efficiency
		fidcache - active file collection
		journal - slash-specific journalling routines
		lconf - lex definitions for slash.conf configuration parser
		mds - RPC messages for metadata exchange
		sb - slash file system superblock routines
		timer - timer subsystem routines, for periodic maintenance
		yconf - yacc rules/codes for slash.conf configuration parser
	slctl - command-line slashd controller
	sliod - I/O server
		control - control interface definitions
		rpc - RPC routines specific to sliod
		timer - timer subsystem routines, for periodic maintenance
	slioctl - command-line sliod controller
zest - root of zest-specific code

how to leverage the make infrastructure for building your programs in a PFL-friendly manner:

the structure of our make system is a bit weird but is so to allow programs/sources/paths
to move around without requiring many pathname references to be updated.

next, adding sources: simple add all the source file your program consists of to SRCS:

  SRCS+=	foo.c
  SRCS+=	bar.c

libraries are frowned upon for a number of reasons.  instead, add to your program SRCS
variable:

  SRCS+=	${PFL_BASE}/psc_util/crc.c

there are a number of convenience variables for large SRCS additions:

  userland LNET socket networking device:
	SRCS+=	${LNET_SOCKLND_SRCS}

  userland LNET cfs (miscellaenous) library (used by all LNET code):
	SRCS+=	${LNET_CFS_SRCS}

  userland LNET library (used by all LNET networking devices):
	SRCS+=	${LNET_LIB_SRCS}

  userland LNET portals networking device:
	SRCS+=	${LNET_PTLLND_SRCS}

  PSC RPC library:
	SRCS+=	${PSCRPC_SRCS}

next, specify additional optional environmental factors:

	INCLUDES - a list of -I<path> passed to gcc and a few other places
	DEFINES - a list of -D<name>[=<value>] directives
	LDFLAGS - linker flags such as -lfoo or -L<path>

notes:
	- don't use CFLAGS directly unless you only want to pass a flag to gcc.
	  e.g. if you add CFLAGS+=-DFOO, then this define won't propagated to
	  other targets, such as "make define" or "make lint"
	- avoid hardcoding paths as much as possible, e.g.

		$ INCLUDES+=	-I${ZEST_BASE}/zestrpc

	  instead of

		$ INCLUDES+=	-I../../../zestrpc

	  or

		$ INCLUDES+=	-I${KERNEL_BASE}/include

	  instead of

		$ INCLUDES+=	-I/usr/src/kernels/2.6.9/include/stuff

finally, include rules for the project the program is a part of

  include ${SLASHMK}

writing a pfl program

- PFL initialization
  (o) creates the subsystem facility to allow fine-grained logging capabilities
  (o) initializes the thread table
  (o) other minor environmental initialization

threadtable registration
  - any code that runs in a thread that does a threadtable lookup for himself
    will crash unless that thread has been registered with pscthr_init().
    this routine can register a thread which has already been spawned (e.g.
    the main/first thread) or can be used to spawn off new threads with the
    specified start/main routine
  - most PFL code uses the threadtable, so make sure your threads pscthr_init()
    before invoking PFL routines, otherwise the table lookup will fail and
    you'll crash!

- LNET initialization
  (o) a global lnet_thrspawnf is used to callback to your code from LNET to
      "properly" spawn off new threads (by whatever that means for your
      application) for its dirty work.  in many cases, this means we just
      call pscthr_init() and spawn the thread off.

- storing connection-local data: PSCRPC maintains a structure psc_export
  associated with each request which contains the peer information and
  contains a member void *rq->rq_export->exp_privdata which can be used
  to store an application-specific (or task-specific) structure to
  associate data with the peer.

-


